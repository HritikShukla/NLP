{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HritikShukla/NLP/blob/master/Tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN0dqcIITBRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c081497d-4bd3-4ce9-f2ca-349116f50894"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import urllib, json\n",
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)\n",
        "df=df.head()\n",
        "print(df)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
            "0  A32T2H8150OJLU  B00000JBLH  ...     1094169600   09 3, 2004\n",
            "1  A3MAFS04ZABRGO  B00000JBLH  ...     1197676800  12 15, 2007\n",
            "2  A1F1A0QQP2XVH5  B00000JBLH  ...     1293840000   01 1, 2011\n",
            "3   A49R5DBXXQDE5  B00000JBLH  ...     1145404800  04 19, 2006\n",
            "4  A2XRMQA6PJ5ZJ8  B00000JBLH  ...     1375574400   08 4, 2013\n",
            "5  A2JFOHC9W629IE  B00000JBLH  ...     1011744000  01 23, 2002\n",
            "6  A38NELQT98S4H8  B00000JBLH  ...     1168992000  01 17, 2007\n",
            "7   AA8M6331NI1EN  B00000JBLH  ...     1384387200  11 14, 2013\n",
            "8  A25C2M3QF9G7OQ  B00000JBLU  ...     1291680000   12 7, 2010\n",
            "9  A1RTVWTWZSIC94  B00000JBLU  ...     1385942400   12 2, 2013\n",
            "\n",
            "[10 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmmlpbWuJKdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7273c3a5-ac63-4cde-dd73-51d8455f8a42"
      },
      "source": [
        "def nltk_token(sentence):\n",
        "  token=dict()\n",
        "  token[\"Tokens\"] = word_tokenize(sentence)\n",
        "  return token\n",
        "\n",
        "df['reviewText_tokens']= df['reviewText'].apply(nltk_token)\n",
        "print(df[\"reviewText_tokens\"])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Tokens': ['I', 'bought', 'my', 'first', 'HP1...\n",
            "1    {'Tokens': ['WHY', 'THIS', 'BELATED', 'REVIEW'...\n",
            "2    {'Tokens': ['I', 'have', 'an', 'HP', '48GX', '...\n",
            "3    {'Tokens': ['I', ''ve', 'started', 'doing', 'm...\n",
            "4    {'Tokens': ['For', 'simple', 'calculations', '...\n",
            "5    {'Tokens': ['While', 'I', 'do', 'n't', 'have',...\n",
            "6    {'Tokens': ['I', ''ve', 'had', 'an', 'HP', '12...\n",
            "7    {'Tokens': ['Bought', 'this', 'for', 'my', 'bo...\n",
            "8    {'Tokens': ['This', 'is', 'a', 'well-designed'...\n",
            "9    {'Tokens': ['I', 'love', 'this', 'calculator',...\n",
            "Name: reviewText_tokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_tzEb3_JOp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1482c66e-c8db-4564-88a9-1882eedc638e"
      },
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "tokenize = MWETokenizer()\n",
        "\n",
        "def mwe_token(sentence):\n",
        "  Mwe=dict()\n",
        "  Mwe[\"MWE_tokens\"]=tokenize.tokenize(sentence)\n",
        "  return Mwe\n",
        "\n",
        "df['reviewText_mweTokens']= df['reviewText'].apply(mwe_token)\n",
        "print(df[\"reviewText_mweTokens\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'MWE_tokens': ['I', ' ', 'b', 'o', 'u', 'g', ...\n",
            "1    {'MWE_tokens': ['W', 'H', 'Y', ' ', 'T', 'H', ...\n",
            "2    {'MWE_tokens': ['I', ' ', 'h', 'a', 'v', 'e', ...\n",
            "3    {'MWE_tokens': ['I', ''', 'v', 'e', ' ', 's', ...\n",
            "4    {'MWE_tokens': ['F', 'o', 'r', ' ', 's', 'i', ...\n",
            "5    {'MWE_tokens': ['W', 'h', 'i', 'l', 'e', ' ', ...\n",
            "6    {'MWE_tokens': ['I', ''', 'v', 'e', ' ', 'h', ...\n",
            "7    {'MWE_tokens': ['B', 'o', 'u', 'g', 'h', 't', ...\n",
            "8    {'MWE_tokens': ['T', 'h', 'i', 's', ' ', 'i', ...\n",
            "9    {'MWE_tokens': ['I', ' ', 'l', 'o', 'v', 'e', ...\n",
            "Name: reviewText_mweTokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcad03x9JUZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9fedef64-c118-4eb4-98d8-025d49bc0084"
      },
      "source": [
        "def nltk_postag(sentence):\n",
        "  pos=dict()\n",
        "  pos[\"Position_Tags\"]=nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
        "  return pos\n",
        "\n",
        "df['reviewText_postntag']= df['reviewText'].apply(nltk_postag)\n",
        "print(df[\"reviewText_postntag\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Position_Tags': [('I', 'PRP'), ('bought', 'V...\n",
            "1    {'Position_Tags': [('WHY', 'WRB'), ('THIS', 'N...\n",
            "2    {'Position_Tags': [('I', 'PRP'), ('have', 'VBP...\n",
            "3    {'Position_Tags': [('I', 'PRP'), (''ve', 'VBP'...\n",
            "4    {'Position_Tags': [('For', 'IN'), ('simple', '...\n",
            "5    {'Position_Tags': [('While', 'IN'), ('I', 'PRP...\n",
            "6    {'Position_Tags': [('I', 'PRP'), (''ve', 'VBP'...\n",
            "7    {'Position_Tags': [('Bought', 'NNP'), ('this',...\n",
            "8    {'Position_Tags': [('This', 'DT'), ('is', 'VBZ...\n",
            "9    {'Position_Tags': [('I', 'PRP'), ('love', 'VBP...\n",
            "Name: reviewText_postntag, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQOzsX_eM6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "621b1da4-2754-42b9-da01-68e2c93e2395"
      },
      "source": [
        "\n",
        "def nltk_adjectives(sentence):\n",
        "  adj=dict()\n",
        "  adj[\"adjectives\"] = [token for token, pos in nltk.pos_tag(word_tokenize(sentence)) if pos.startswith('J')]\n",
        "  return adj\n",
        "\n",
        "df['reviewText_adjectives']= df['reviewText'].apply(nltk_adjectives)\n",
        "print(df[\"reviewText_adjectives\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'adjectives': ['first', 'difficult', 'many', ...\n",
            "1    {'adjectives': ['old', 'satisfied', 'ower', 'f...\n",
            "2    {'adjectives': ['more', 'more', 'old', 'flawle...\n",
            "3    {'adjectives': ['more', 'good', 'available', '...\n",
            "4    {'adjectives': ['simple', 'best', 'financial',...\n",
            "5    {'adjectives': ['hard', 'undergraduate', 'quic...\n",
            "6    {'adjectives': ['available', 'original', 'esse...\n",
            "7                  {'adjectives': ['great', 'little']}\n",
            "8    {'adjectives': ['well-designed', 'simple', 'ty...\n",
            "9    {'adjectives': ['big', 'calculate', 'easy', 'e...\n",
            "Name: reviewText_adjectives, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}